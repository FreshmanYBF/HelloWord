
/*=========================================================	
Chapter I  			URL与资源
=========================================================*/

URL语法由9部分组成：
	<scheme>://<user>:<password>@<host>:<port>/<path>;<param>?<query>#<frag>
		
		param(参数)和query(查询条件)使用Key=Value形式表示，KV之间使用&连接
		frag(片段)：标识一个字段中的某个片段, 表示只想获取片段。
					但是服务器只会响应整个对象，而不会只响应片段，所以frag用于客户端，客户端从整个响应对象中摘取出片段显示出来
					
1、相对URL

在HTML中可以使用相对URL来表示资源，相对URL为保持一组资源的可移植性可提供了一种便捷方式 

	有了 “ 基础URL ” 才能对 “ 相对URL ” 进行转换
	
2、自动扩展URL
用户输入的时候尝试自动扩展URL，这样用户无需输入完整的URL

（1）主机名扩展
（2）历史扩展。将历史访问的URL存储起来


3、URL的字符组成规则

URL应该是可移植的(可用于各种不同的协议，而有些协议会剥离一些特殊字符)，可供人阅读的(不能由不可见，不能打印的字符)，完整的(转义机制将不安全的字符编码为安全字符)

（1）URL通用字母表和编码规则

URL字符集：ASCII
	问题：有些特殊字符，二进制数据无法使用ASCII满足完整性的同时表示出来
	解决方法：转义序列。通过转义序列，使用ASCII字符集对任意字符值或数据进行编码。
	编码机制：通过一种 “转义” 表示法来表示不安全的字符
			  转义表示法：一个百分号(%)后面跟两个表示字符ASCII码的十六进制数   例如，空格，ASCII为32(0x20)，则表示为%20
			  
（2）字符限制
一些字符不在定义的ASCII可打印字符集中，有些字符与某些因特网网关和协议产生混淆

/*=========================================================	
Chapter II  		  HTTP报文
=========================================================*/

起始行
首部 ( 会给出一些与实体有关的信息, 例如Content-Type, Content-Length )
报文实体

1、CRLF
每行以回车换行符结束——回车符 ASCII码13，换行符 ASCII码10
	但是有的使用单个换行符作为终止，应用程序也应该能够解析
由于历史原因，很多在没有实体的主体部分时，省略最后的CRLF，虽然这是不符合规范的，但是应用程序应该接受(历史遗留问题)。

2、状态码
（1）100~199	信息提示
100 Continue			C端需要在Except首部中指定
	C端Except首部携带100 Continue，等待接收到S端的100 Continue，收到它就会继续发送实体，但如果超时仍然未收到，则也要发送实体
	S端如果在没有响应100 Continue前，就收到实体。那么它应该继续接受实体，然后返回最终的响应
101 Switch Protocols 	C端需要在Update中指定
	S端正在将协议切换成C端Update首部所列的协议 
（2）200~299 成功

（3）300~399 重定向
S端响应首部中Location字段会指出重定向资源的URL

（4）400~499 客户端错误
405 Method Not Allowed
406 Not Acceptable			C端说明可以接受什么类型的实体，S端不匹配的话则返回
408 Request Timeout		
412 Precondition Failed		C端发起了条件请求，且其中一个条件失败时使用了。C端使用Except首部发起条件请求
417 Exception Failed 		请求的Expect请求首部包含一个期望，但服务器无法满足此期望时，使用此状态码

（5）500~599 服务端错误

3、首部
（1）通用首部——请求和响应中均可用
Trailer				如果报文采用了分块传输编码(chunked transfer encoding)方式，可以用该字段列出位于报文拖挂部分的首部集合
Transfer-Encoding	对报文采用什么编码方式
Update				想要“升级”使用的新版本或协议
Via 				显示报文经过的中间节点（代理、网关）
（2）请求首部
Client-IP			C端IP地址
From				客户端用户的E-mail地址
Referer				提供了包含当前请求URI的文档的URL
User-Agent			将发起请求的应用程序名称告诉S端

Accept				C端的喜好和能力，告知S端。Accept 媒体类型；Accept-Charset 字符集；Accept-Encoding 编码方式；Accept-Language 语言

Except				条件请求首部，C端为请求加上某些限制。If-Match 匹配标记；If-Modified-Since 指定某个日期后资源被修改过则响应该请求；If-None-Match 标记不匹配
														 If-Range 对文档某个范围进行请求；If-Unmodified-Since 从某个日期开始，资源从未被修改过
														 Range	范围请求

Authorization		认证
Cookie				客户端用它向服务器传送一个令牌——它并不是真正的安全首部，但确实隐含了安全功能
Cookie2				说明请求端支持的cookie版本
	
（3）响应首部
Age					响应持续时间
Retry-After			如果资源不可用，在此日期或时间重试

Accept-Range 		S端可接受的范围类型

Set-Cookie			不是真正的安全首部，但隐含有安全功能；可以在C端设置一个令牌，一遍服务器对C端进行标识

（4）实体首部——描述主体的长度和内容，或资源自身
Allow 				可以对实体执行的请求方法
Location			实际URL

Content-Base
Content-Encoding
Content-Language
Content-Location
Content-MD5			主体的MD5校验和
Content-Range		在整个资源中实体表示的字节范围

ETag 				与此实体相关的实体标记
Expires 	`		实体不再有效，要从原始的源端再次获取此实体的日期和时间
Last-Modified 		这个实体最后一次修改的日期和时间

（5）扩展首部
首部可以分为多行，多出来的每行前面至少要有一个空格或制表符

4、方法
GET
HEAD：响应报文只返回首部
PUT
POST：通常用来支持表单
TRACE：请求可能穿过防火墙、代理、网关或其他一些应用程序，TRACE可以看到最后一战是否修改了原始报文。
OPTIONS：请求Web服务器告知其支持的各种功能
DELETE： 

/*=========================================================	
Chapter III  		  TCP连接
=========================================================*/

HTTP连接管理应当从实验与经验中学习

（1）HTTP是如何使用TCP连接的
（2）TCP连接的时延、瓶颈以及存在的障碍
（3）HTTP的优化，包括并行连接、keep-alive（持久连接）和管道化管理
（4）管理连接时应该以及不应该做的事情

 如果要编写复杂的，快速运行的HTTP应用程序，需要学习的与TCP内部原理及性能有关的知识，推荐《TCP/IP》详解
 
 TCP，分组交换，可靠，通过IP分组的小数据块来发送。<Source IP, Destination IP, Source TCP Port, Destination TCP Port>
 
*===============================	
	   对TCP性能的考虑
===============================*/
对TCP性能的考虑

HTTP事务的时延：
	DNS查询，连接，请求，数据处理，响应，关闭
	
1、时延的主要原因
（1）DNS解析。URI中的主机名转换成一个IP可能需要数十秒，但是大多数HTTP客户端都有本地缓存，且主机名都是常用站点，所以通常很快解析
（2）TCP连接建立（三次握手）。SYN同步，SYN+ACK确认，ACK确认
（3）发送请求报文，读取请求报文，处理请求报文，发送响应报文
（4）关闭连接（四次挥手）。可以不用管是否挥手成功。

硬件，网络和服务器的负载，请求和响应报文的尺寸，C与S之间的距离，TCP协议的技术复杂性都会对时延产生影响


2、性能聚焦区域
（1）TCP连接建立握手
C端发送SYN说明这是一个连接，S端响应SYN+ACK，说明连接请求被接受，C端回送ACK表示连接已成功建立

有的时候很多响应报文都可以放入一个IP分组中去，导致小的HTTP事务，在TCP建立上花费50%的时间甚至更多

（2）TCP慢启动拥塞控制

TCP传输的性能还取决于TCP连接的使用期。

	TCP连接会随着时间进行 自我调谐 ，起初会限制连接的最大速度，如果数据传输成功，会随着时间推移提高传输的速度。
		这种调谐成为慢启动，用于防止因特网的突然过载和拥塞。
		
	由于已调谐的连接会更快一下，所以一些新的连接的传输速度通常比已经交换过一些数量的数据慢一些。
		为了重用已经建立的连接，HTTP增加了 ” 持久连接 “


（3）数据聚集的Nagle算法

Nagle算法和TCP_NODELAY

应用程序可以向TCP协议栈写入任意尺寸的字节，但是每个TCP段中都至少装载了40个字节的标记和首部，所以当TCP发送大量包含少量数据的分组时，网络性能就会严重下降

	Nagle算法试图在发送一个分组之前，将大量TCP数据绑定在一起，以提高网络效率。
		Nagle鼓励发送全尺寸(LAN上最大尺寸大约是1500字节，因特网上是几百字节)，
		只有当其他分组都被确认后，Nagle算法才允许发送非全尺寸的分组
		
	延迟确认和Nagle算法引起的性能问题
		（1）延迟确认，需要接收方延迟等到有能捎带确认包的分组，延迟100~200ms
		（2）Nagle算法，需要等到足够发送一个全尺寸的包
		C等待 n ms，向网络中发送了一个全尺寸包，那么延时了 n ms；接收方接收到分组后，等待能捎带确认包的分组，延迟了m ms(100~200ms)，没有等到，最终发送确认包，延时了 m ms
		建立连接的步骤是，发送SYN(n)，响应SYN+ACK(m)，发送响应ACK(m), 发送数据包(<=n)，接收响应ACK(m), 响应发送FIN(m), 发送FIN(n), 响应ACK(m)
		n+m+m+n+m+m+n+m  500ms~100ms + 3n
		
	HTTP应用程序常常会在自己的栈中设置参数 TCP_NODELAY ，禁用 Nagle算法，提高性能。但是这种情况下要确保向TCP写入大块的数据，这样就不会产生一堆小分组。


（4）用于捎带确认的TCP延迟确认算法
每个TCP段都有一个序列号和数据完整性校验和。段被接收后，接收者回送小的确认分组。如果发送者在 ” 指定的窗口时间 “ 内没有收到确认信息，则认为分组丢失或破坏，则重发数据

由于分组很小，确认报文常常与输出的数据分组结合在一起

为了增加确认报文找到同向传输分组的可能性，很多TCP栈都实现了一种 “ 延迟确认 ” 算法。
		延迟确认算法会在一个特定的 “ 窗口时间 ” (通常是100~200ms)内将输出确认存放在缓冲区中，以寻找能够捎带它的输出分组
		如果在那个时间段内没有输出数据分组，就将确认信息放在单独的分组中传送
	
	但是HTTP具有双峰特征的请求-应答行为，降低了捎带信息的可能。当希望有相反方向回传分组时，偏偏没有那么多了。延迟确认算法可能引入相当大的延迟。根据所使用OS不同，可以禁用或调整延迟确认算法。

（5）TIME_WAIT时延和端口耗尽

TIME_WAIT端口耗尽是很严重的性能问题

	当某个TCP端点关闭TCP连接时，会在内存中维护一个小的控制块，用来记录最近所关闭连接的IP地址和端口号。
	这类信息会维持一段时间，通常是所估计的最大分段使用期的两倍(称为2MSL，通常为2分钟)左右，以确保这段时间不会创建具有相同地址和端口号的连接。
		(目前高速路由器的使用，使得重复分组几乎不可能在连接关闭的几分钟之后，出现在服务器上 —— 分组要么已经送到，要么被丢弃)
		(有些操作系统可以将2MSL设置为一个较小的值，但是修改时需要注意，如果太小，使得控制块销毁后，分组还在网络上传输，那么新生成的具有相同的地址和端口号的连接就会被这个分组破坏)
	
	连接率问题
		在基准测试环境中，通常只有一台或几台用来产生流量的计算机连接到某个系统中
		极端情况下，只有一个C端和一个Web服务器的情况下。
		使用TIME_WAIT防止端口号重用时，由于2MSL的限制，假设设备上可用的源端口号为60000个，那么60000/120s，就是500次/s，连接率不高于500次/s，才能确认不会遇到TIME_WAIT端口耗尽问题
		
/*=========================================================	
Chapter IV  		  HTTP连接
=========================================================*/

HTTP连接优化技术


1、Connection首部

C端和最终的S端可能存在很多HTTP中间实体（代理、高速缓存）

Connection首部可以承载3种不同类型的标签
（1）HTTP首部字段名，列出了只与此连接有关的首部。——Connection选项可能不允许转发
（2）任意标签值，用于描述此连接的非标准选项
（2）值close，说明操作完之后关闭这条持久连接


2、串行事务处理时延

串行需要等待——2的传送需要等1完成；每次的新连接引入新的连接时延和慢启动时延

提高HTTP的连接性能
	（1）并行连接
		通过多条TCP连接发起并发的HTTP请求
	（2）持久连接
		重用TCP连接，以消除连接及关闭时延
	（3）管道化连接
		通过 ” 共享 “ 的TCP连接发起并发的HTTP请求
	（4）复用的连接
		交替传送请求和响应报文

4、并行连接

（1）并行连接可能会提高页面加载的速度——因为连接时延和慢启动时延存在了重叠的部分
（2）并行连接不一定更快——当带宽有限时，并行连接都受限于有限的可竞争带宽
（3）并行连接数量收到限制 —— 浏览器会限制并行连接的数量，若不限制，则服务器的连接并发量将会很庞大

5、持久连接

事务处理结束后仍然保持在打开状态的TCP连接 —— 避免了连接建立的耗时和慢启动的时延


6、持久以及并行连接

持久连接与并行连接配合使用，可能是最高效的方式
	合理的管理持久连接，否则会出现大量的空闲连接
	
（1）持久连接有两种类型

HTTP/1.0+ "keep-alive"

HTTP/1.1 "persistent"


/*===============================	
	    keep-alive
===============================*/

HTTP 1.0 开始支持
HTTP 1.1 已经没有对keep-alive的说明
但是keep-alive还在使用

 Connection: Keep-Alive

1、Keep-Alive选项
Connect: Keep-Alive时可用
Keep-Alive首部可以指定参数，限定所处理的事务数量和超时时间

（1）timeout，连接保持的时间。期望值
（2）max，处理的事务数量，再次期间保持连接
（3）其他，可自动逸

2、Keep-Alive连接的限制和规则

（1）Connection: Keep-Alive必须和所有希望保持持久连接的一起发送
（2）服务器支持且允许持久连接，则返回Connection: Keep-Alive
（3）为了有效的区分同一个连接种的不同的事务，不许传送正确的Content-Length
（4）代理和网关必须执行Connection首部的规划。转发或删除Connection首部及命名字段
（5）应该忽略来自HTTP 1.0的Connection首部字段，因为它们可能是比较老的代理服务器误转发的
（6）除非重复发送请求会产生其他一些副作用，否则如果在客户端收到完整的响应之前连接就关闭了，客户端一定要做好重试请求的准备

3、Keep-Alive和哑代理

Connection: Keep-Alive 首部应该只会对这条离开客户端的TCP链路产生影响
Connection: Keep-Alive 首部是逐跳首部，只适用于单条传输链路 —— 源端和目的端IP组成一条传输链路

（1）Connection首部和哑代理

一些代理，尤其是不理解Connection首部，而且不知道在沿着转发链路将其发送出去之前，应该将该首部删除的代理
	它们只是 将字节从一个连接转发到另一个连接中去，不对COnnection首部进行特殊处理 —— 盲代理
	
C端    <=>      代理     <=>     S端

	C端发送keep-alive给代理，代理与S端建立连接，并透传给S端keep-alive，S端接收到keep-alive，保持keep-alive连接
	S端响应keep-alive连接，代理透传keep-alive连接，C端接收到keep-alive连接，与代理建立keep-alive连接
	但是代理对keeep-alive一无所知，它等待S端断开连接，并且在收到C端的同一连接中的另一个事务时，进行忽略
	最终只有等待keep-alive连接超时
	
（2）代理和逐跳首部

现代的代理都绝不转发Connection首部，和其他一些逐跳首部

（3）插入Proxy-Connection

使用Proxy-Connection告诉代理想要建立keep-alive连接 
	对于盲代理，透传Proxy-Connection，Web收到后忽略非标准的Proxy-Connection 
	对于能识别Proxy-Connection的代理，其与Web服务器建立keep-alive连接，与C端建立keep-alive连接 
	仅能处理单个代理的情况

如果存在多个代理，则Proxy-Connection，会在盲代理那里透传，在Proxy-Connection代理那里建立keep-alive连接，从而导致忙代理被建立keep-alive连接而不自知


/*===============================	
	    persistent
===============================*/

HTTP 1.1 支持，默认情况下是激活的，发送Connection: close，事务处理完成后关闭

1、持久连接的限制与规则

（1）持久连接需要确保每个报文的Conntent-Length是正确的
（2）代理必须能够处理持久连接 —— 每个持久连接仅适用于一跳传输
（3）设备可以主动关闭连接
（4）持久连接必须能够从异步的关闭中恢复出来。只要不存在可能会积累起来的副作用，客户端都应该重试这条请求
（5）一个客户端对任何服务器或代理最多只能维护两条持久连接，以防服务器过载



/*===============================	
	    管道化 连接
===============================*/

HTTP 1.1允许在持久连接上可选地使用 ” 请求管道 “ —— 管道 类似 消息队列，先进先出，请求按序发送，响应按序返回

	在响应达到之前，可以将多条请求放入队列。
	当第一条请求通过网络达到服务器时，第二条和第三条请求也可以开始发送了
	在高时延网络条件下，可以降低网络的环回时间，提高性能
	
1、对管道化连接的限制

（1）如果连接不是持久的，就不应该使用管道
（2）必须按照与请求相同的顺序回送HTTP响应。HTTP报文中没有序列号，因此如果收到的响应失序了，就没办法与请求匹配起来
（3）C端必须做好连接会在任意时刻关闭的准备，还要准备好重发所有未完成的管道化请求
（4）C端不应该用管道化的方式发送会产生副作用的请求（比如POST）。
	出错的时候，管道化的方式会阻碍客户端了解服务器执行的是一系列管道化请求中的哪一些。
	由于无法安全地重试POST这样的非幂等请求，所以出错的时候，存在某些方法永远不会被执行的风险



/*===============================	
	    关闭连接
===============================*/

1、”任意“解除连接

（1）C/S可以在任意时刻关闭连接
（2）服务器在一条报文发送完毕后关闭连接，但是它无法确认C端还有没有数据要发送，如果C端正在发送数据，C端就会出现连接错误

2、Content-Length及截尾操作

（1）如果服务器省略了Content-Length首部，或者包含错误的长度指示，这样就要依赖服务器发出的连接关闭来说明数据的真实末尾
（2）如果接收端是个缓存代理，接收端就不应该缓存这条响应。代理应该将有问题的报文原封不动的转发出去，而不应该试图 “校正” Content-Length

3、连接关闭容限、重试以及幂等性

（1）幂等性：一个事务执行多次，得到的结果都是相同的，那么就是幂等的。
（2）服务端关闭连接时，C端对于未收到响应的非幂等性的事务，需要判断是否重试。—— 管道化连接一般只传输幂等性事务

4、正常关闭连接

TCP连接是双向，TCP连接的每一端都有一个输入队列和一个输出队列，用于数据的读或写

（1）完全关闭与半关闭
close() 完全关闭
shutdown() 半关闭
应用程序可以关闭TCP输入和输出信道中任意一个

（2）TCP关闭及重置错误

简单的HTTP应用程序可以只使用完全关闭
	当应用程序开始与很多其他类型HTTP客户端、服务器和代理进行对话且开始使用管道化持久连接时，使用半关闭来防止对等实体收到非预期的写入操作就变得很重要了
		关闭输出信道总是安全 —— 即不再往外发送数据。这种关闭一定是在发送完最后的数据包后再进行关闭
			对等端会从其缓冲区中读出所有数据后收到一条通知，说明流结束了。
		关闭连接信道的输入信道比较危险，除非你知道对端不打算再发送其他数了
			如果对端向你已经关闭的输入信道发送数据，操作系统就会向另一端的机器回送一条TCP ” 连接被对端重置 “ 的报文
				大多数 操作系统 都会将这种情况作为很严重的错误来处理，删除对端还未读取的所有缓存数据
					对管道化连接来说，这非常糟糕 —— 当收到 ” 连接被对端重置 “， 操作系统会清空还未读取的输入缓冲区，当你读取数据时会得到一个 ” 连接对端被重置 “ 的错误
					
（3）正常关闭
首先关闭 “输出信道”，然后等待另一端的对等实体关闭它的 ”输出信道”。
	但是无法确保对等实体会实现半关闭，或对其进行检查。
	所以在关闭 “输出信道” 之后，然后周期性地检查其输入信道的状态。并在超时时间后，强制关闭，以节省资源。

/*=========================================================	
Chapter V  		  	Web服务器
=========================================================*/	

通用软件Web服务器
嵌入式Web服务器

Web服务器：
	（1）建立连接
	（2）接收请求
	（3）处理请求
	（4）访问资源 —— 访问URL中的资源
	（5）构建响应
	（6）发送响应
	（7）记录事务处理过程

1、建立连接

建立连接后，Web可以知道C端的IP，可以通过 “反向DNS”(比较耗时) 知道C端的主机名，可以通过ident协议询问C端的身份
	ident协议监听 113 端口，描述主机身份的协议
了解主机的身份有利于日志的记录

2、接收请求报文

服务器架构：
（1）单线程Web服务器 —— 一个连接一个连接的处理
（2）多进程及多线程Web服务器 —— 多个线程或进程处理多个连接
（3）复用I/O的服务器 —— 监听所有连接的活动，连接状态有变化则进行少量的处理，处理结束后放在监听集合中，等待下一次状态变化
（4）复用的多线程Web服务器 —— 一般用于多核，每个核采用 复用I/O


3、处理请求

解析请求报文，可以把报文解析为内部数据类型，例如
	struct {
		method:
		version:
		uri:
		header count: 
		headers: [K, V] ...
		body:
	}

4、对资源的映射及访问

（1）docroot直接映射 —— URI对应服务器上同名的资源

（2）docroot虚拟托管 —— 虚拟托管的Web服务器会在同一个台Web服务器上提供多个Web站点，每个站点有自己独有的文档根目录

（3）docroot用户主目录 —— 以 /~ 开头，加上用户名，例如 GET /~bob/index.html HTTP/1.0

（4）访问控制 —— 例如摘要认证

5、构建响应

响应主体类型
响应的Content-Length
响应主体 

（1）重定向
Location首部包含了内容的新地址或优选地址的URI
	永久搬离的资源
	临时搬离的资源
	URL增强 
	负载均衡
	服务器关联
	规范目录名称

6、发送响应

7、记录日志


/*=========================================================	
Chapter VI  		  	  代理
=========================================================*/	

HTTP代理，代理与网关，如何部署，如何配置浏览器使用代理
	Via首部和Trace方法来记录报文传输路径上的代理服务器链
	基于代理的HTTP访问控制
	代理与C端交互，代理与服务器交互
	
1、代理的概念
代表客户端完成事务处理的中间人

（1）公共代理
众多C端所共享的代理，集中式代理的成本更低，效率更高，更容管理。某些代理，比如高速缓存代理，会利用用户间共同的请求，这样用户越多，代理就越有用

（2）私有代理
某个客户端专用。有的浏览器会运行一些小型代理，以便提高浏览器特性，提高性能或免费提供ISP服务

2、代理与网关

代理连接的是两个或多个使用相同协议的应用程序

网关连接的是两个或多个使用不同协议的端点 —— 协议转换

网关与代理的极限慢慢模糊，一些商用代理也会实现网关的功能。


/*===============================	
		为什么使用代理
===============================*/

代理可以看到并接触到所有流过的HTTP流量，所以代理可以对其进行修改，以实现很多有用的增值Web服务

1、儿童过滤器

2、文档访问控制
代理集中对客户端的访问能力进行控制 —— 这在大型企业或分布式机构中很有用。
	在大量的服务器和资源之间使用统一的访问控制策略
	
3、安全防火墙
控制流入流出，检查数据

4、Web缓存
缓存维护常用的文档副本

5、反向代理
可以认为代理客户端，因为它接收C端发送给Web服务器的真实请求 —— 可能没有Proxy-xxx这样的中间步骤
	反向代理可以根据请求发起与其他服务器的通信

6、内容路由器
根据因特网流量状况以及内容类型将请求导向特定的Web服务器

7、转码器
在转给服务器之前修改主体格式

8、匿名者
将报文中的身份特性信息删除 —— 例如IP地址，From首部，cookie，URI会话ID等


/*===============================	
		如何部署代理
===============================*/

1、如何部署代理
（1）出口代理
部署在C端本地网络的出口点，可以提供防火墙保护，或降低带宽费用，提高因特网流量的性能

	C <---本地网络---> 代理 <----因特网-----> 服务器

（2）入口代理
放在ISP访问点上，处理来自客户端的聚合请求。ISP使用缓存代理来存储常用文档的副本。
	
	C <--基站-->  代理 <---因特网----> 服务器

（3）反向代理

部署在网络边缘，在Web服务器之前，作为替代物使用。
	它们可以处理所有传送给Web服务器的请求，并在必要时向服务器请求资源
	通常会直接冒充Web服务器的名字和IP地址
	
	C <----因特网----> 代理 <----本地网络------> 服务器

（4）网络交换代理

将具有足够处理能力的代理放在网络之间的因特网对等交换点上，通过缓存来减轻因特网节点的拥塞，并对流量进行监视

	C <----因特网----> 代理 <-----因特网----> 服务器
	
	
2、代理的层次结构

存在多级代理

（1）静态层次
代理1总是将报文转发给代理2，代理2总是转发给代理3
（2）动态层次
代理根据负载，请求类型，网络质量，路径等因素转发报文给其他代理

3、代理如何获取流量

在C端设置代理；在交换/路由设备上配置代理；在DNS上配置代理；在Web服务器上配置重定向

（1）修改客户端。在客户端手动配置代理
（2）修改网络。拦截流量，将其导入代理 —— 这种拦截通常依赖于监视HTTP流量的交换设备及路由设备
（3）修改DNS的命名空间。
（4）修改Web服务器。将客户端请求重定向到代理上

/*===============================	
	代理请求带来的问题
===============================*/

1、代理请求中的URI和服务器请求中的URI有什么不同

（1）发给代理的URI一般是完整的 —— 方案/主机/端口/URI
（2）可以使用Host首部来指定具体的某个主机 —— 对于虚拟Web服务器，多个Web站点运行在同一台设备上，可以使用Host指定不同的站点
（3）发给服务器请求中的URI是部分URI

2、拦截和反向代理是如何将服务器主机信息隐藏起来的

客户端无法区分当前是否在和拦截代理或反向代理通信
（1）反向代理冒充了服务器的主机名或IP
（2）拦截代理一般配置了原始的IP和端口


3、修改URI的规则
代理服务器在转发报文时修改请求URI的话 —— 可能会给下游服务器带来一些互操作问题

4、代理是怎样影响浏览器的智能URI自动完成机制，或主机名扩展机制的
（1）没有代理时，会自动填充扩展 或 根据配置的DNS域添加域名后缀
（2）有显示代理时，URI会直接发送给代理
（3）有拦截代理时，浏览器会自动扩展主机名，直到DNS成功为止
		客户对于拦截代理是无感知的，因为客户端无感知，所以客户端使用解析出来的停用IP与拦截代理建立连接后以为这个IP能用
		当解析出来的IP地址对应的服务器可能停用时，拦截代理需要提供容错机制 —— 对Host首部进行DNS解析，尝试所有IP
		
/*===============================	
		追踪报文
===============================*/

代理转发愈来愈常见

1、Via首部

	Via首部列出了与报文途径的每个中间点（代理或网关）有关的信息。报文每经过一个节点，都必须将这个中间节点添加到Via列表
	代理发送请求中前，在Via首部插入自己的独特字符串，并在查找这个字符串，检查是否存在路由循环
存在隐私问题

2、TRACE方法
可以用来调试代理
（1）Max-Forwards首部，用来限制代理的跳数



/*===============================	
		 代理的互操作性
===============================*/

客户端、服务器和代理是由不同厂商构建，实现的是不同版本的HTTP规范
	
对于代理不支持的首部和方法，代理应该尽量尝试将报文转发到下一跳节点上去

1、OPTIONS ： 发现可选特性的支持

OPTIONS * HTTP/1.1  ——  请求整个服务器支持功能

OPTIONS URI HTTP/1.1  ——  请求某个资源支持的功能

/*=========================================================	
Chapter VII  		  	  缓存
=========================================================*/	

减少冗余数据传输
缓解网络瓶颈 —— 本地网络带宽一般比远程网络带宽大，传输速率更快，如果本地有缓存副本，就缓解了远程网络带宽的压力
降低距离时延 —— 光速在超远距离时延也会明显，当请求的元素过多，累加起来时更加明显
缓解原始服务器压力 —— 缓存可以环节原始服务器的压力，破坏 “ 瞬间拥塞 ”（同一时刻大量请求访问导致的拥塞）

1、缓存应该放在什么网络位置？
2、如何保持缓存副本的新鲜度？
3、缓存如何与其他缓存和服务器通信？


/*===============================	
		缓存如何保持新鲜度
===============================*/
速度
	缓存命中 > 再验证 > 缓存未命中

“新鲜度检测” —— 被称为 “HTTP再验证”

	（1）如何检测
		HTTP定义了一些特殊的请求，可以快速检测内容是否是最新的
			缓存对副本进行 再验证请求 ，如果内容没有变化会返回 304 Not Modified
			收到304，缓存会把副本标记为暂时新鲜
	（2）检测策略
		缓存通常会包含数百万的文档，而且网络带宽很珍贵
		大部分缓存只有在客户端发起请求，并且副本旧得足够需要检测的时候，才会对副本进行再验证
		
1、文档命中率和字节命中率

二者是度量缓存性能的标准

	文档命中率说明阻止了多少事务通常外部网络，降低了整体时延
	字节命中率说明了组织了多少字节传向因特网，节省了带宽

2、如何判断响应是否来自缓存

HTTP标准中并没有定义响应来自缓存或原始服务器
	但是可以通过Date首部的值与当前时间进行比较，时间较早说明来自缓存
	也可以通过Age首部分辨出这条响应的使用期
	
3、如何保持副本的新鲜度 —— 算法

	HTTP有一些简单的机制可以在不要求服务器记住有哪些缓存拥有其文档副本的情况，保持已缓存数据与服务器数据之间充分的一致。
	HTTP将这些机制称为 “ 文档过期 ” 和 “ 服务器再验证 ” 
（1）文档过期
Date首部：对象创建日期
Expires首部：使用绝对日期 —— 过期时间
Cache-Control首部：使用相对日期 —— 过期时间

（2）服务器再验证
缓存询问原始服务器文档是否发生变化
	再验证显示发生变化，则缓存会获取一份新的文档副本
	再验证显示没有发生变化，则缓存只需要获取新的首部 —— 一个新的过期日期，并对缓存的首部进行更新就可以了

（3）条件首部再验证
If-Modified-Since: <date> —— date之后资源发生了变化，才响应该请求
If-None-Match: <tag> —— 当date并不能精确的描述内容发生了实质性的变化时，可以使用 tag

（4）强弱验证器
实体标签验证和最近修改时间验证都是验证器
弱验证器在条件首部中以 W 开头（weak），可以实现非强匹配

/*===============================	
   缓存的网络拓扑以及缓存处理
===============================*/


1、层次拓扑
一级缓存，二级缓存等

2、网状拓扑

内容路由器缓存 —— 根据内容以及一些策略选择某个缓存服务器或原始服务器

3、缓存的处理步骤

（1）接收
（2）解析
（3）查询
（4）新鲜度检测
（5）创建响应 —— Date首部是原对象的创建日期，不应该修改
（6）发送
（7）日志


/*===============================	
		控制缓存的能力
===============================*/

Cache-Control: no-store —— 禁止缓存对响应进行复制
Cache-Control: no-cache —— 缓存对对象进行再验证之前不能直接返回
Cache-Control: must-revalidate —— 再验证之前不能使用该副本
Cache-Control: max-age —— 文档处于新鲜的秒数
Expires: 


1、Apache Web服务器是如何支持缓存控制的

Apache Web服务器提供了几种设置HTTP缓存控制首部的机制


2、缓存与广告

有的广告商是通过广告的访问次数来获取利益的，但是做的好的缓存会使得原始服务器的广告访问次数大大下降
	为了得到真实的访问次数，可以使用日志迁移 —— 将缓存的关于该对象的命中日志迁移给服务器
	RFC 2227定义了一个首部Meter，这个首部会周期性地将对特定URL的命中次数回送给服务器

/* =========================================
Chapter VIII	网关、隧道及中继
============================================ */

1、网关

网关 把一种协议请求 转换成 另一种协议请求

	网关应用程序和服务应用程序运行在不同的设备上 —— 
	网关应用程序和服务应用程序运行在同一个设备上 —— 网关应用编程接口（Common Gateway Interface）
		CGI是一个标准接口集，Web服务器可以用它来状态程序以响应对特定URL的HTTP请求，并收集程序输出数据，放到HTTP响应中
		
	网关可以放在本地网络出口，或者放在服务器远程网络入口
	
		
2、隧道

	Web隧道，可以通过HTTP应用程序访问使用非HTTP协议的应用程序
	
	Web隧道是用HTTP的 CONNECT 方法建立起来的。
		CONNECT方法请求 隧道网关 创建一条到达任意目的服务器和端口的TCP连接，并对客户端和服务器之间的后继数据进行盲转发
	
	由于隧道可以使用HTTP透传任何其他协议，所以存在安全隐患 —— 可以在允许客户端使用隧道前进行代理认证；或者只对某些知名端口开启隧道
	
3、中继

HTTP中继是没有完全遵循HTTP规范的简单HTTP代理。
	中继负责处理HTTP中建立连接的部分，然后对字节进行盲目转发
	
	 
/* =========================================
Chapter IX	   	Web机器人
============================================ */

自动发起Web请求的应用程序

1、爬虫

递归地追踪Web链接的机器人，沿着HTML超链创建的网络”爬行“，所以称之为爬虫

（1）根URL集合
（2）链接的提取
将绝对URL提取出来，添加到URL集合中
将相对URL转换成绝对URL，添加到URL集合中
（3）避免环路的出现
判断某个URL是否被访问过，当URL量级达到数亿时，维护至少需要搜索树或散列表
大规模Web爬虫维护URL使用的技术：
	树和散列表：使用搜索树或散列表来记录已访问的URL
	有损的存在位图：用散列将URL转成一个定长的数字，这个数字在”位数组“中有一个标志位，访问过则置位
	检查点：要将已访问的URL存在硬盘
	分类：使用分布式和集群爬虫
别名与机器人环路
	URL存在”别名“，及URL不同，但是指向同一资源
	可以通过规范化URL消除部分别名：
		没有端口则添加端口80
		将所有转义符%xx都转成等价字符
		删除#标签
文件系统连接环路
	文件系统中的符号连接造成的潜在环路
动态虚拟Web空间
	生成动态内容的同时生成新的URL，使得爬虫不断地探索这个虚无的Web空间，直到URL满了
避免循环和重复
	首先没有一劳永逸，简单明了的方法。一般表现良好的爬虫都会包含一组试探行为
		规范URL
		广度优先爬行 —— 广度优先可以将环路影响最小化；使用深度优先，一头扎进单个站点中就可能会跳入环路
		节流：限制从一个Web站点获取的页面数
		限制URL的大小
		URL/站点黑名单
		模式检测：文件系统的符号链接造成的环路会遵循某种模式
		内容指纹：计算出链接文本的内容校验和。
		人工监视


2、机器人的HTTP

机器人的HTTP应该如何实现 —— 比如请求应该如何组包

虽然机器人倾向于只支持最小的HTTP集
（1）首部
	User-Agent：告知服务器机器人的名字
	From：提供机器人的用户/管理者Email
	Accept：可以接收的媒体类型
	Referer：提供包含了当前请求URL的文档的URL
	Host：指定需要访问的域名 —— 有的时候同一个URL在不同的站点上或者说是完全不同的内容
（2）条件请求
（3）对响应的处理
状态码
实体
（4）User-Agent优化
有的Web站点可能会针对User-Agent做一些优化 —— 比如如果是爬虫就响应错误的内容

3、行为不当的机器人

（1）失控
影响了服务器向其他用户提供服务的性能
（2）失效的URL
向Web站点访问不存在URL —— 爬虫需要保证其URL集合的有效性
（3）很长的错误URL
（4）爱打听的机器人 —— 访问了隐私数据
（5）动态网关访问 —— 

4、拒绝机器人访问

	自愿约束技术 

存储访问控制信息存储在robots.txt中，说明了机器人可以访问哪些资源
	机器人在访问之前先获取robots.txt文件
		（1）获取robotstxt —— 机器人使用GET来获取robots.txt
		（2）请求robots.txt的响应码 —— 200则解析；404则表示没有；401或403则表示访问受限；503则目前服务器无法访问；3XX则重定向
	robots.txt文件格式
		文件中有三种类型行 —— 空行，注释行，规则行（K:V）
		（1）User-Agent
			描述哪些机器人可以访问
		（2）Disallow和Allow
			描述哪些URL可以访问
	HTML的robot-control元标签
		通过HTML的META标签来实现 —— <meta name="robots" content=""></meta>

5、机器人规范
	http://www.robotstxt.org/wc/guidelines.html  一些机器人规范建议
	
	
6、搜索引擎
	搜索引擎是Web机器人的主要来源
	（1）搜索引擎构建了一些名为 “ 全文索引 ” 的复杂本地数据库，装在了Web页面的所有内容
		全文索引 —— 索引的叶子节点包含了整个Web页面
	（2）相关性排名 —— 对搜索引擎搜索出来的结果进行排名，按照索引单词与页面内容的相关性排序
	（3）框架								
	Web搜索用户  <->  Web搜索网关  <->  全文索引数据库
											  ^
											  |
											 爬虫
											  ^
											  |
										  Web服务器
	用户向Web搜索引擎网关发布一条请求
	网关程序对请求进行解析，并将查询转成搜索全文索引所需的表达式
	对全文索引搜索出的结果进行相关性排序，展示给用户



/* =========================================
Chapter IX	HTTP-NG 下一代HTTP方案
============================================ */

HTTP的发展中存在的问题：
	复杂性
	可扩展性
	性能
	传输依赖性
	
1、HTTP-NG
（1）模块化及功能增强
将协议模块划分为三层
	报文传输层 —— 报文的编码，格式。
					端点之间的不透明传输。传输层支持各种子协议栈（比如无线环境下的协议栈），
					主要负责高效报文传输及处理方面的问题
	远程调用层 —— 定义了 请求/响应 的功能。项目组建议本层使用 二进制连接协议
	Web应用层 —— 内容管理逻辑。HTTP方法，首部参数
	
	
2、报文传输层

	关心报文的有效传输，不关心报文的含义和目的
	为报文传输提供了一个API，无论底层采用什么网络协议栈都可以使用

关注报文传输的性能：
	（1）对报文进行管道化和批量传输，以降低时延
	（2）重用连接，以降低时延，提传输带宽
	（3）同一条连接上并行地复用多个报文流，在防止报文流饿死的同时优化共享连接
	（4）对报文进行有效地分段，使报文边界的确定更加容易
WebMUX报文协议
	（1）复用连接 —— 在 一条连接 上动态、高效地交错传递多个数据流
	（2）流量控制 —— 
	
3、远程调用
	
	本层提供了通用的请求/响应框架，客户端可通过此框架调用对服务器资源的操作
	
二进制连接协议
	定义了一些 对象类型 ，并为每种对象类型分配了一组方法
	



/* =========================================
Chapter X	  识别、认证与安全
============================================ */	




/* =========================
	识别 —— 实现用户个性化
=========================== */	

客户端识别与cookie机制
	（1）承载用户信息的HTTP首部
	（2）C端IP跟踪
	（3）用户登录，用认证方式来识别用户
	（4）胖URL，一种在URL中嵌入识别信息的技术

	
1、HTTP首部
	From
	User-Agent 
	Referer 				用户是从这个页面上一句链接跳转过来的
	Authorization 			用户名和密码
	Client-IP 
	X-Forwarded-For 
	Cookie					服务器产生的ID标签

2、C端IP地址
	DHCP，NAT，网关/代理等的存在使得这种方式并不实用 
	
3、用户登录

	不同的网站可能需要不同的用户名和密码
	用户登录使得网站的访问变得繁琐，使得网站的跳转变得低效
	
	有解决方法 —— Cookie
	
4、胖URL
	在客户端访问某个URL时，将用户信息扩展到这个URL结尾
	这种方式使得URL的复用性变差 —— 无法缓存，无法共享
			URL变得臃肿，服务器负荷加重

5、Cookie

Cookie是当前识别用户并实现持久会话的最好方式
	大多数缓存和浏览器都不允许对任何cookie的内容进行缓存
	
（1）cookie的类型
会话cookie：
	临时cookie，记录用户访问时的设置和偏好，用户退出会话cookie被删除
持久cookie：
	存储在硬盘上。维护周期性访问站点的某个用户的配置或登录名

如果设置了Discard，或没有设置Expires或Max-Age参数来扩展说明过期时间，那么就是一个会话cookie

（2）cookie工作原理
用户首次访问Web服务器，服务器使用 Set-Cookie或Set-Cookie2 HTTP响应首部表示客户端
客户端再次请求服务器，使用 Cookie 带上服务器为自己添加的身份
	cookie中包含由 name=value 构成的列表

（3）cookie罐：客户端的状态
客户端需要存储cookie信息
	cookie —— 域名，URI，name=value，有效期等

（4）不同站点使用不同的cookie
cookie的域属性
	使用 domain=value，控制哪些站点可以看到这个cookie
cookie的路径属性
	使用 path=value，控制访问某个路径可以获得这个cookie

（5）cookie成分
cookie规范有两个版本，版本0应用更广泛
	版本0定义了Set-Cookie响应首部、cookie请求首部以及用于控制cookie的字段
		Set-Cookie: name=value [; expires=date] [; path=path] [; domain=domain] [; secure]
		Cookie: name1=value1 [; name2=value2]
		
			Set-Cookie属性
				NAME=VALUE
				Expires：一个日期，说明cookie的实际生存期
				Domain
				Path
				Secure：如果包含这一属性，那么只有HTTP使用SSL安全连接时才会发送cookie
	
	版本1的(RFC 2965)Set-Cookie2和Cookie2

（6）会话跟踪
在Set-Cookie中添加session-id=value，同时使用重定向，记录用户的访问踪迹
如果客户端禁用了cookie，可以使用胖URL，实现一些基本的标识功能

（7）cookie与缓存
cookie与缓存的规则并没有很好地建立。
一些指导性建议：
	如果无法缓存文档，要将其标示出来
	缓存Set-Cookie首部要小心 —— 如果向多个用户发送相同的Set-Cookie首部会破坏用户的定位
	小心处理带有Cookie首部的请求 —— 带有Cookie的请求表示请求的结果可能是隐私的。一定要将私有内容标识为不可缓存
	
（8）cookie、安全性和隐私

