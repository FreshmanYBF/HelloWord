
/*=========================================================	
Chapter I  			URL与资源
=========================================================*/

URL语法由9部分组成：
	<scheme>://<user>:<password>@<host>:<port>/<path>;<param>?<query>#<frag>
		
		param(参数)和query(查询条件)使用Key=Value形式表示，KV之间使用&连接
		frag(片段)：标识一个字段中的某个片段, 表示只想获取片段。
					但是服务器只会响应整个对象，而不会只响应片段，所以frag用于客户端，客户端从整个响应对象中摘取出片段显示出来
					
1、相对URL

在HTML中可以使用相对URL来表示资源，相对URL为保持一组资源的可移植性可提供了一种便捷方式 

	有了 “ 基础URL ” 才能对 “ 相对URL ” 进行转换
	
2、自动扩展URL
用户输入的时候尝试自动扩展URL，这样用户无需输入完整的URL

（1）主机名扩展
（2）历史扩展。将历史访问的URL存储起来


3、URL的字符组成规则

URL应该是可移植的(可用于各种不同的协议，而有些协议会剥离一些特殊字符)，可供人阅读的(不能由不可见，不能打印的字符)，完整的(转义机制将不安全的字符编码为安全字符)

（1）URL通用字母表和编码规则

URL字符集：ASCII
	问题：有些特殊字符，二进制数据无法使用ASCII满足完整性的同时表示出来
	解决方法：转义序列。通过转义序列，使用ASCII字符集对任意字符值或数据进行编码。
	编码机制：通过一种 “转义” 表示法来表示不安全的字符
			  转义表示法：一个百分号(%)后面跟两个表示字符ASCII码的十六进制数   例如，空格，ASCII为32(0x20)，则表示为%20
			  
（2）字符限制
一些字符不在定义的ASCII可打印字符集中，有些字符与某些因特网网关和协议产生混淆

/*=========================================================	
Chapter II  		  HTTP报文
=========================================================*/

起始行
首部 ( 会给出一些与实体有关的信息, 例如Content-Type, Content-Length )
报文实体

1、CRLF
每行以回车换行符结束——回车符 ASCII码13，换行符 ASCII码10
	但是有的使用单个换行符作为终止，应用程序也应该能够解析
由于历史原因，很多在没有实体的主体部分时，省略最后的CRLF，虽然这是不符合规范的，但是应用程序应该接受(历史遗留问题)。

2、状态码
（1）100~199	信息提示
100 Continue			C端需要在Except首部中指定
	C端Except首部携带100 Continue，等待接收到S端的100 Continue，收到它就会继续发送实体，但如果超时仍然未收到，则也要发送实体
	S端如果在没有响应100 Continue前，就收到实体。那么它应该继续接受实体，然后返回最终的响应
101 Switch Protocols 	C端需要在Update中指定
	S端正在将协议切换成C端Update首部所列的协议 
（2）200~299 成功

（3）300~399 重定向
S端响应首部中Location字段会指出重定向资源的URL

（4）400~499 客户端错误
405 Method Not Allowed
406 Not Acceptable			C端说明可以接受什么类型的实体，S端不匹配的话则返回
408 Request Timeout		
412 Precondition Failed		C端发起了条件请求，且其中一个条件失败时使用了。C端使用Except首部发起条件请求
417 Exception Failed 		请求的Expect请求首部包含一个期望，但服务器无法满足此期望时，使用此状态码

（5）500~599 服务端错误

3、首部
（1）通用首部——请求和响应中均可用
Trailer				如果报文采用了分块传输编码(chunked transfer encoding)方式，可以用该字段列出位于报文拖挂部分的首部集合
Transfer-Encoding	对报文采用什么编码方式
Update				想要“升级”使用的新版本或协议
Via 				显示报文经过的中间节点（代理、网关）
（2）请求首部
Client-IP			C端IP地址
From				客户端用户的E-mail地址
Referer				提供了包含当前请求URI的文档的URL
User-Agent			将发起请求的应用程序名称告诉S端

Accept				C端的喜好和能力，告知S端。Accept 媒体类型；Accept-Charset 字符集；Accept-Encoding 编码方式；Accept-Language 语言

Except				条件请求首部，C端为请求加上某些限制。If-Match 匹配标记；If-Modified-Since 指定某个日期后资源被修改过则响应该请求；If-None-Match 标记不匹配
														 If-Range 对文档某个范围进行请求；If-Unmodified-Since 从某个日期开始，资源从未被修改过
														 Range	范围请求

Authorization		认证
Cookie				客户端用它向服务器传送一个令牌——它并不是真正的安全首部，但确实隐含了安全功能
Cookie2				说明请求端支持的cookie版本
	
（3）响应首部
Age					响应持续时间
Retry-After			如果资源不可用，在此日期或时间重试

Accept-Range 		S端可接受的范围类型

Set-Cookie			不是真正的安全首部，但隐含有安全功能；可以在C端设置一个令牌，一遍服务器对C端进行标识

（4）实体首部——描述主体的长度和内容，或资源自身
Allow 				可以对实体执行的请求方法
Location			实际URL

Content-Base
Content-Encoding
Content-Language
Content-Location
Content-MD5			主体的MD5校验和
Content-Range		在整个资源中实体表示的字节范围

ETag 				与此实体相关的实体标记
Expires 	`		实体不再有效，要从原始的源端再次获取此实体的日期和时间
Last-Modified 		这个实体最后一次修改的日期和时间

（5）扩展首部
首部可以分为多行，多出来的每行前面至少要有一个空格或制表符

4、方法
GET
HEAD：响应报文只返回首部
PUT
POST：通常用来支持表单
TRACE：请求可能穿过防火墙、代理、网关或其他一些应用程序，TRACE可以看到最后一战是否修改了原始报文。
OPTIONS：请求Web服务器告知其支持的各种功能
DELETE： 

/*=========================================================	
Chapter III  		  TCP连接
=========================================================*/

HTTP连接管理应当从实验与经验中学习

（1）HTTP是如何使用TCP连接的
（2）TCP连接的时延、瓶颈以及存在的障碍
（3）HTTP的优化，包括并行连接、keep-alive（持久连接）和管道化管理
（4）管理连接时应该以及不应该做的事情

 如果要编写复杂的，快速运行的HTTP应用程序，需要学习的与TCP内部原理及性能有关的知识，推荐《TCP/IP》详解
 
 TCP，分组交换，可靠，通过IP分组的小数据块来发送。<Source IP, Destination IP, Source TCP Port, Destination TCP Port>
 
*===============================	
	   对TCP性能的考虑
===============================*/
对TCP性能的考虑

HTTP事务的时延：
	DNS查询，连接，请求，数据处理，响应，关闭
	
1、时延的主要原因
（1）DNS解析。URI中的主机名转换成一个IP可能需要数十秒，但是大多数HTTP客户端都有本地缓存，且主机名都是常用站点，所以通常很快解析
（2）TCP连接建立（三次握手）。SYN同步，SYN+ACK确认，ACK确认
（3）发送请求报文，读取请求报文，处理请求报文，发送响应报文
（4）关闭连接（四次挥手）。可以不用管是否挥手成功。

硬件，网络和服务器的负载，请求和响应报文的尺寸，C与S之间的距离，TCP协议的技术复杂性都会对时延产生影响


2、性能聚焦区域
（1）TCP连接建立握手
C端发送SYN说明这是一个连接，S端响应SYN+ACK，说明连接请求被接受，C端回送ACK表示连接已成功建立

有的时候很多响应报文都可以放入一个IP分组中去，导致小的HTTP事务，在TCP建立上花费50%的时间甚至更多

（2）TCP慢启动拥塞控制

TCP传输的性能还取决于TCP连接的使用期。

	TCP连接会随着时间进行 自我调谐 ，起初会限制连接的最大速度，如果数据传输成功，会随着时间推移提高传输的速度。
		这种调谐成为慢启动，用于防止因特网的突然过载和拥塞。
		
	由于已调谐的连接会更快一下，所以一些新的连接的传输速度通常比已经交换过一些数量的数据慢一些。
		为了重用已经建立的连接，HTTP增加了 ” 持久连接 “


（3）数据聚集的Nagle算法

Nagle算法和TCP_NODELAY

应用程序可以向TCP协议栈写入任意尺寸的字节，但是每个TCP段中都至少装载了40个字节的标记和首部，所以当TCP发送大量包含少量数据的分组时，网络性能就会严重下降

	Nagle算法试图在发送一个分组之前，将大量TCP数据绑定在一起，以提高网络效率。
		Nagle鼓励发送全尺寸(LAN上最大尺寸大约是1500字节，因特网上是几百字节)，
		只有当其他分组都被确认后，Nagle算法才允许发送非全尺寸的分组
		
	延迟确认和Nagle算法引起的性能问题
		（1）延迟确认，需要接收方延迟等到有能捎带确认包的分组，延迟100~200ms
		（2）Nagle算法，需要等到足够发送一个全尺寸的包
		C等待 n ms，向网络中发送了一个全尺寸包，那么延时了 n ms；接收方接收到分组后，等待能捎带确认包的分组，延迟了m ms(100~200ms)，没有等到，最终发送确认包，延时了 m ms
		建立连接的步骤是，发送SYN(n)，响应SYN+ACK(m)，发送响应ACK(m), 发送数据包(<=n)，接收响应ACK(m), 响应发送FIN(m), 发送FIN(n), 响应ACK(m)
		n+m+m+n+m+m+n+m  500ms~100ms + 3n
		
	HTTP应用程序常常会在自己的栈中设置参数 TCP_NODELAY ，禁用 Nagle算法，提高性能。但是这种情况下要确保向TCP写入大块的数据，这样就不会产生一堆小分组。


（4）用于捎带确认的TCP延迟确认算法
每个TCP段都有一个序列号和数据完整性校验和。段被接收后，接收者回送小的确认分组。如果发送者在 ” 指定的窗口时间 “ 内没有收到确认信息，则认为分组丢失或破坏，则重发数据

由于分组很小，确认报文常常与输出的数据分组结合在一起

为了增加确认报文找到同向传输分组的可能性，很多TCP栈都实现了一种 “ 延迟确认 ” 算法。
		延迟确认算法会在一个特定的 “ 窗口时间 ” (通常是100~200ms)内将输出确认存放在缓冲区中，以寻找能够捎带它的输出分组
		如果在那个时间段内没有输出数据分组，就将确认信息放在单独的分组中传送
	
	但是HTTP具有双峰特征的请求-应答行为，降低了捎带信息的可能。当希望有相反方向回传分组时，偏偏没有那么多了。延迟确认算法可能引入相当大的延迟。根据所使用OS不同，可以禁用或调整延迟确认算法。

（5）TIME_WAIT时延和端口耗尽

TIME_WAIT端口耗尽是很严重的性能问题

	当某个TCP端点关闭TCP连接时，会在内存中维护一个小的控制块，用来记录最近所关闭连接的IP地址和端口号。
	这类信息会维持一段时间，通常是所估计的最大分段使用期的两倍(称为2MSL，通常为2分钟)左右，以确保这段时间不会创建具有相同地址和端口号的连接。
		(目前高速路由器的使用，使得重复分组几乎不可能在连接关闭的几分钟之后，出现在服务器上 —— 分组要么已经送到，要么被丢弃)
		(有些操作系统可以将2MSL设置为一个较小的值，但是修改时需要注意，如果太小，使得控制块销毁后，分组还在网络上传输，那么新生成的具有相同的地址和端口号的连接就会被这个分组破坏)
	
	连接率问题
		在基准测试环境中，通常只有一台或几台用来产生流量的计算机连接到某个系统中
		极端情况下，只有一个C端和一个Web服务器的情况下。
		使用TIME_WAIT防止端口号重用时，由于2MSL的限制，假设设备上可用的源端口号为60000个，那么60000/120s，就是500次/s，连接率不高于500次/s，才能确认不会遇到TIME_WAIT端口耗尽问题
		
/*=========================================================	
Chapter IV  		  HTTP连接
=========================================================*/

HTTP连接优化技术


1、Connection首部

C端和最终的S端可能存在很多HTTP中间实体（代理、高速缓存）

Connection首部可以承载3种不同类型的标签
（1）HTTP首部字段名，列出了只与此连接有关的首部。——Connection选项可能不允许转发
（2）任意标签值，用于描述此连接的非标准选项
（2）值close，说明操作完之后关闭这条持久连接


2、串行事务处理时延

串行需要等待——2的传送需要等1完成；每次的新连接引入新的连接时延和慢启动时延

提高HTTP的连接性能
	（1）并行连接
		通过多条TCP连接发起并发的HTTP请求
	（2）持久连接
		重用TCP连接，以消除连接及关闭时延
	（3）管道化连接
		通过 ” 共享 “ 的TCP连接发起并发的HTTP请求
	（4）复用的连接
		交替传送请求和响应报文

4、并行连接

（1）并行连接可能会提高页面加载的速度——因为连接时延和慢启动时延存在了重叠的部分
（2）并行连接不一定更快——当带宽有限时，并行连接都受限于有限的可竞争带宽
（3）并行连接数量收到限制 —— 浏览器会限制并行连接的数量，若不限制，则服务器的连接并发量将会很庞大

5、持久连接

事务处理结束后仍然保持在打开状态的TCP连接 —— 避免了连接建立的耗时和慢启动的时延


6、持久以及并行连接

持久连接与并行连接配合使用，可能是最高效的方式
	合理的管理持久连接，否则会出现大量的空闲连接
	
（1）持久连接有两种类型

HTTP/1.0+ "keep-alive"

HTTP/1.1 "persistent"


/*===============================	
	    keep-alive
===============================*/

HTTP 1.0 开始支持
HTTP 1.1 已经没有对keep-alive的说明
但是keep-alive还在使用

 Connection: Keep-Alive

1、Keep-Alive选项
Connect: Keep-Alive时可用
Keep-Alive首部可以指定参数，限定所处理的事务数量和超时时间

（1）timeout，连接保持的时间。期望值
（2）max，处理的事务数量，再次期间保持连接
（3）其他，可自动逸

2、Keep-Alive连接的限制和规则

（1）Connection: Keep-Alive必须和所有希望保持持久连接的一起发送
（2）服务器支持且允许持久连接，则返回Connection: Keep-Alive
（3）为了有效的区分同一个连接种的不同的事务，不许传送正确的Content-Length
（4）代理和网关必须执行Connection首部的规划。转发或删除Connection首部及命名字段
（5）应该忽略来自HTTP 1.0的Connection首部字段，因为它们可能是比较老的代理服务器误转发的
（6）除非重复发送请求会产生其他一些副作用，否则如果在客户端收到完整的响应之前连接就关闭了，客户端一定要做好重试请求的准备

3、Keep-Alive和哑代理

Connection: Keep-Alive 首部应该只会对这条离开客户端的TCP链路产生影响
Connection: Keep-Alive 首部是逐跳首部，只适用于单条传输链路 —— 源端和目的端IP组成一条传输链路

（1）Connection首部和哑代理

一些代理，尤其是不理解Connection首部，而且不知道在沿着转发链路将其发送出去之前，应该将该首部删除的代理
	它们只是 将字节从一个连接转发到另一个连接中去，不对COnnection首部进行特殊处理 —— 盲代理
	
C端    <=>      代理     <=>     S端

	C端发送keep-alive给代理，代理与S端建立连接，并透传给S端keep-alive，S端接收到keep-alive，保持keep-alive连接
	S端响应keep-alive连接，代理透传keep-alive连接，C端接收到keep-alive连接，与代理建立keep-alive连接
	但是代理对keeep-alive一无所知，它等待S端断开连接，并且在收到C端的同一连接中的另一个事务时，进行忽略
	最终只有等待keep-alive连接超时
	
（2）代理和逐跳首部

现代的代理都绝不转发Connection首部，和其他一些逐跳首部

（3）插入Proxy-Connection

使用Proxy-Connection告诉代理想要建立keep-alive连接 
	对于盲代理，透传Proxy-Connection，Web收到后忽略非标准的Proxy-Connection 
	对于能识别Proxy-Connection的代理，其与Web服务器建立keep-alive连接，与C端建立keep-alive连接 
	仅能处理单个代理的情况

如果存在多个代理，则Proxy-Connection，会在盲代理那里透传，在Proxy-Connection代理那里建立keep-alive连接，从而导致忙代理被建立keep-alive连接而不自知


/*===============================	
	    persistent
===============================*/

HTTP 1.1 支持，默认情况下是激活的，发送Connection: close，事务处理完成后关闭

1、持久连接的限制与规则

（1）持久连接需要确保每个报文的Conntent-Length是正确的
（2）代理必须能够处理持久连接 —— 每个持久连接仅适用于一跳传输
（3）设备可以主动关闭连接
（4）持久连接必须能够从异步的关闭中恢复出来。只要不存在可能会积累起来的副作用，客户端都应该重试这条请求
（5）一个客户端对任何服务器或代理最多只能维护两条持久连接，以防服务器过载



/*===============================	
	    管道化 连接
===============================*/

HTTP 1.1允许在持久连接上可选地使用 ” 请求管道 “ —— 管道 类似 消息队列，先进先出，请求按序发送，响应按序返回

	在响应达到之前，可以将多条请求放入队列。
	当第一条请求通过网络达到服务器时，第二条和第三条请求也可以开始发送了
	在高时延网络条件下，可以降低网络的环回时间，提高性能
	
1、对管道化连接的限制

（1）如果连接不是持久的，就不应该使用管道
（2）必须按照与请求相同的顺序回送HTTP响应。HTTP报文中没有序列号，因此如果收到的响应失序了，就没办法与请求匹配起来
（3）C端必须做好连接会在任意时刻关闭的准备，还要准备好重发所有未完成的管道化请求
（4）C端不应该用管道化的方式发送会产生副作用的请求（比如POST）。
	出错的时候，管道化的方式会阻碍客户端了解服务器执行的是一系列管道化请求中的哪一些。
	由于无法安全地重试POST这样的非幂等请求，所以出错的时候，存在某些方法永远不会被执行的风险



/*===============================	
	    关闭连接
===============================*/

1、”任意“解除连接

（1）C/S可以在任意时刻关闭连接
（2）服务器在一条报文发送完毕后关闭连接，但是它无法确认C端还有没有数据要发送，如果C端正在发送数据，C端就会出现连接错误

2、Content-Length及截尾操作

（1）如果服务器省略了Content-Length首部，或者包含错误的长度指示，这样就要依赖服务器发出的连接关闭来说明数据的真实末尾
（2）如果接收端是个缓存代理，接收端就不应该缓存这条响应。代理应该将有问题的报文原封不动的转发出去，而不应该试图 “校正” Content-Length

3、连接关闭容限、重试以及幂等性

（1）幂等性：一个事务执行多次，得到的结果都是相同的，那么就是幂等的。
（2）服务端关闭连接时，C端对于未收到响应的非幂等性的事务，需要判断是否重试。—— 管道化连接一般只传输幂等性事务

4、正常关闭连接

TCP连接是双向，TCP连接的每一端都有一个输入队列和一个输出队列，用于数据的读或写

（1）完全关闭与半关闭
close() 完全关闭
shutdown() 半关闭
应用程序可以关闭TCP输入和输出信道中任意一个

（2）TCP关闭及重置错误

简单的HTTP应用程序可以只使用完全关闭
	当应用程序开始与很多其他类型HTTP客户端、服务器和代理进行对话且开始使用管道化持久连接时，使用半关闭来防止对等实体收到非预期的写入操作就变得很重要了
		关闭输出信道总是安全 —— 即不再往外发送数据。这种关闭一定是在发送完最后的数据包后再进行关闭
			对等端会从其缓冲区中读出所有数据后收到一条通知，说明流结束了。
		关闭连接信道的输入信道比较危险，除非你知道对端不打算再发送其他数了
			如果对端向你已经关闭的输入信道发送数据，操作系统就会向另一端的机器回送一条TCP ” 连接被对端重置 “ 的报文
				大多数 操作系统 都会将这种情况作为很严重的错误来处理，删除对端还未读取的所有缓存数据
					对管道化连接来说，这非常糟糕 —— 当收到 ” 连接被对端重置 “， 操作系统会清空还未读取的输入缓冲区，当你读取数据时会得到一个 ” 连接对端被重置 “ 的错误
					
（3）正常关闭
首先关闭 “输出信道”，然后等待另一端的对等实体关闭它的 ”输出信道”。
	但是无法确保对等实体会实现半关闭，或对其进行检查。
	所以在关闭 “输出信道” 之后，然后周期性地检查其输入信道的状态。并在超时时间后，强制关闭，以节省资源。

/*=========================================================	
Chapter V  		  	Web服务器
=========================================================*/	

通用软件Web服务器
嵌入式Web服务器

Web服务器：
	（1）建立连接
	（2）接收请求
	（3）处理请求
	（4）访问资源 —— 访问URL中的资源
	（5）构建响应
	（6）发送响应
	（7）记录事务处理过程

1、建立连接

建立连接后，Web可以知道C端的IP，可以通过 “反向DNS”(比较耗时) 知道C端的主机名，可以通过ident协议询问C端的身份
	ident协议监听 113 端口，描述主机身份的协议
了解主机的身份有利于日志的记录

2、接收请求报文

服务器架构：
（1）单线程Web服务器 —— 一个连接一个连接的处理
（2）多进程及多线程Web服务器 —— 多个线程或进程处理多个连接
（3）复用I/O的服务器 —— 监听所有连接的活动，连接状态有变化则进行少量的处理，处理结束后放在监听集合中，等待下一次状态变化
（4）复用的多线程Web服务器 —— 一般用于多核，每个核采用 复用I/O


3、处理请求

解析请求报文，可以把报文解析为内部数据类型，例如
	struct {
		method:
		version:
		uri:
		header count: 
		headers: [K, V] ...
		body:
	}

4、对资源的映射及访问

（1）docroot直接映射 —— URI对应服务器上同名的资源

（2）docroot虚拟托管 —— 虚拟托管的Web服务器会在同一个台Web服务器上提供多个Web站点，每个站点有自己独有的文档根目录

（3）docroot用户主目录 —— 以 /~ 开头，加上用户名，例如 GET /~bob/index.html HTTP/1.0

（4）访问控制 —— 例如摘要认证

5、构建响应

响应主体类型
响应的Content-Length
响应主体 

（1）重定向
Location首部包含了内容的新地址或优选地址的URI
	永久搬离的资源
	临时搬离的资源
	URL增强 
	负载均衡
	服务器关联
	规范目录名称

6、发送响应

7、记录日志


/*=========================================================	
Chapter VI  		  	  代理
=========================================================*/	

HTTP代理，代理与网关，如何部署，如何配置浏览器使用代理
	Via首部和Trace方法来记录报文传输路径上的代理服务器链
	基于代理的HTTP访问控制
	代理与C端交互，代理与服务器交互
	
1、代理的概念
代表客户端完成事务处理的中间人

（1）公共代理
众多C端所共享的代理，集中式代理的成本更低，效率更高，更容管理。某些代理，比如高速缓存代理，会利用用户间共同的请求，这样用户越多，代理就越有用

（2）私有代理
某个客户端专用。有的浏览器会运行一些小型代理，以便提高浏览器特性，提高性能或免费提供ISP服务

2、代理与网关

代理连接的是两个或多个使用相同协议的应用程序

网关连接的是两个或多个使用不同协议的端点 —— 协议转换

网关与代理的极限慢慢模糊，一些商用代理也会实现网关的功能。


/*===============================	
		为什么使用代理
===============================*/

代理可以看到并接触到所有流过的HTTP流量，所以代理可以对其进行修改，以实现很多有用的增值Web服务

1、儿童过滤器

2、文档访问控制
代理集中对客户端的访问能力进行控制 —— 这在大型企业或分布式机构中很有用。
	在大量的服务器和资源之间使用统一的访问控制策略
	
3、安全防火墙
控制流入流出，检查数据

4、Web缓存
缓存维护常用的文档副本

5、反向代理
可以认为代理客户端，因为它接收C端发送给Web服务器的真实请求 —— 可能没有Proxy-xxx这样的中间步骤
	反向代理可以根据请求发起与其他服务器的通信

6、内容路由器
根据因特网流量状况以及内容类型将请求导向特定的Web服务器

7、转码器
在转给服务器之前修改主体格式

8、匿名者
将报文中的身份特性信息删除 —— 例如IP地址，From首部，cookie，URI会话ID等


/*===============================	
		如何部署代理
===============================*/

1、如何部署代理
（1）出口代理
部署在C端本地网络的出口点，可以提供防火墙保护，或降低带宽费用，提高因特网流量的性能

	C <---本地网络---> 代理 <----因特网-----> 服务器

（2）入口代理
放在ISP访问点上，处理来自客户端的聚合请求。ISP使用缓存代理来存储常用文档的副本。
	
	C <--基站-->  代理 <---因特网----> 服务器

（3）反向代理

部署在网络边缘，在Web服务器之前，作为替代物使用。
	它们可以处理所有传送给Web服务器的请求，并在必要时向服务器请求资源
	通常会直接冒充Web服务器的名字和IP地址
	
	C <----因特网----> 代理 <----本地网络------> 服务器

（4）网络交换代理

将具有足够处理能力的代理放在网络之间的因特网对等交换点上，通过缓存来减轻因特网节点的拥塞，并对流量进行监视

	C <----因特网----> 代理 <-----因特网----> 服务器
	
	
2、代理的层次结构

存在多级代理

（1）静态层次
代理1总是将报文转发给代理2，代理2总是转发给代理3
（2）动态层次
代理根据负载，请求类型，网络质量，路径等因素转发报文给其他代理

3、代理如何获取流量

在C端设置代理；在交换/路由设备上配置代理；在DNS上配置代理；在Web服务器上配置重定向

（1）修改客户端。在客户端手动配置代理
（2）修改网络。拦截流量，将其导入代理 —— 这种拦截通常依赖于监视HTTP流量的交换设备及路由设备
（3）修改DNS的命名空间。
（4）修改Web服务器。将客户端请求重定向到代理上
